{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build Stoplist - Top 50 Words\n",
        "\n",
        "This notebook builds a stoplist by analyzing word frequencies across documents in the `docs` directory.\n",
        "\n",
        "**Note:** Only the most common English stop words (the, is, and, in, a, etc.) are filtered out.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pathlib, re, collections\n",
        "\n",
        "DOCS = pathlib.Path(\"docs\")\n",
        "OUT = pathlib.Path(\"stoplist_top50.txt\")\n",
        "\n",
        "TOKEN_SPLIT = re.compile(r\"[^A-Za-z]+\")\n",
        "\n",
        "# Common English stop words to filter out (minimal set)\n",
        "STOP_WORDS = {\n",
        "    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from',\n",
        "    'has', 'in', 'is', 'it', 'of', 'on', 'the', 'to',\n",
        "    'was', 'were', 'with', 'you'\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_stoplist_top50(filter_stopwords=True):\n",
        "    counter = collections.Counter()\n",
        "\n",
        "    files = sorted(DOCS.glob(\"*.txt\"))\n",
        "    if not files:\n",
        "        raise SystemExit(\"No files found in ./docs. Run fetch_wiki_docs.py first.\")\n",
        "\n",
        "    for p in files:\n",
        "        txt = p.read_text(encoding=\"utf-8\").lower()\n",
        "        # drop header line \"# TITLE: ...\"\n",
        "        txt = re.sub(r\"^# title: .*?\\n\\n\", \"\", txt, flags=re.IGNORECASE)\n",
        "        tokens = [t for t in TOKEN_SPLIT.split(txt) if t and (len(t) > 1 or t in (\"a\", \"i\"))]\n",
        "        \n",
        "        # Filter out stop words if requested\n",
        "        if filter_stopwords:\n",
        "            tokens = [t for t in tokens if t not in STOP_WORDS]\n",
        "        \n",
        "        counter.update(tokens)\n",
        "\n",
        "    top50 = counter.most_common(50)\n",
        "\n",
        "    # save\n",
        "    with OUT.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"Top 50 words (word\\tcount)\\n\")\n",
        "        for w, c in top50:\n",
        "            f.write(f\"{w}\\t{c}\\n\")\n",
        "    \n",
        "    return top50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering out 22 common stop words\n",
            "Examples: a, an, and, are, as, at, be, by, for, from, has, in, is, it, of, on, the, to, was, were...\n"
          ]
        }
      ],
      "source": [
        "# Show which stop words are being filtered\n",
        "print(f\"Filtering out {len(STOP_WORDS)} common stop words\")\n",
        "print(f\"Examples: {', '.join(sorted(list(STOP_WORDS))[:20])}...\")\n",
        "# Run the function to build the stoplist (with stop word filtering)\n",
        "top50 = build_stoplist_top50(filter_stopwords=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Top 50 Words\n",
              "\n",
              "| Rank | Word | Count |\n",
              "|------|------|-------|\n",
              "| 1 | retrieved | 79 |\n",
              "| 2 | orlandi | 49 |\n",
              "| 3 | county | 47 |\n",
              "| 4 | otto | 43 |\n",
              "| 5 | music | 36 |\n",
              "| 6 | his | 32 |\n",
              "| 7 | dance | 29 |\n",
              "| 8 | chaplin | 29 |\n",
              "| 9 | route | 25 |\n",
              "| 10 | census | 24 |\n",
              "| 11 | so | 24 |\n",
              "| 12 | can | 21 |\n",
              "| 13 | or | 20 |\n",
              "| 14 | espa | 20 |\n",
              "| 15 | single | 19 |\n",
              "| 16 | washington | 19 |\n",
              "| 17 | season | 19 |\n",
              "| 18 | library | 18 |\n",
              "| 19 | we | 18 |\n",
              "| 20 | rave | 18 |\n",
              "| 21 | july | 17 |\n",
              "| 22 | not | 17 |\n",
              "| 23 | de | 17 |\n",
              "| 24 | government | 17 |\n",
              "| 25 | archived | 17 |\n",
              "| 26 | original | 17 |\n",
              "| 27 | beatport | 17 |\n",
              "| 28 | think | 17 |\n",
              "| 29 | state | 16 |\n",
              "| 30 | columbia | 16 |\n",
              "| 31 | walla | 16 |\n",
              "| 32 | he | 16 |\n",
              "| 33 | top | 16 |\n",
              "| 34 | united | 15 |\n",
              "| 35 | states | 15 |\n",
              "| 36 | feat | 15 |\n",
              "| 37 | dancing | 15 |\n",
              "| 38 | national | 14 |\n",
              "| 39 | population | 14 |\n",
              "| 40 | ol | 14 |\n",
              "| 41 | tracklists | 14 |\n",
              "| 42 | cerda | 13 |\n",
              "| 43 | that | 13 |\n",
              "| 44 | no | 13 |\n",
              "| 45 | its | 13 |\n",
              "| 46 | deportivo | 13 |\n",
              "| 47 | show | 13 |\n",
              "| 48 | woodstar | 13 |\n",
              "| 49 | don | 13 |\n",
              "| 50 | stars | 13 |\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Generate and display markdown table\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "markdown_table = \"## Top 50 Words\\n\\n| Rank | Word | Count |\\n|------|------|-------|\\n\"\n",
        "for i, (w, c) in enumerate(top50, 1):\n",
        "    markdown_table += f\"| {i} | {w} | {c} |\\n\"\n",
        "\n",
        "display(Markdown(markdown_table))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
